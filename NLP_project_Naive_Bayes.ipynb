{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on the naive bayes implemented in class for sentiment analysis\n",
    "\n",
    "dataset : train + test (80:20)\n",
    "\n",
    "Task: binary\n",
    "Labels: 0 (not ironic), 1 (ironic)\n",
    "File format: a tab-separated file with one line per tweet containing per line the tweet index, a binary classification label, and the tweet text.\n",
    "\n",
    "1) cleaned version \n",
    "without hashtags & explained emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the environement & Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test data converted into a panda DataFrame'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'D:\\\\documents\\\\_KAIST\\\\s4\\\\NLP\\\\projet\\\\data\\\\SemEval2018-Task3-master\\\\datasets\\\\'\n",
    "DATA_TRAIN = DATA_DIR + 'train\\\\SemEval2018-T3-train-taskA.txt'\n",
    "DATA_TEST = DATA_DIR + 'test_TaskA\\\\SemEval2018-T3_input_test_taskA.txt'\n",
    "LABEL_TEST = DATA_DIR + 'goldtest_TaskA\\\\SemEval2018-T3_gold_test_taskA_emoji.txt'\n",
    "#print(DATA_TRAIN)\n",
    "# headers are given by the first row. conversion into a csv file\n",
    "train = pd.read_table(DATA_TRAIN, header=0)\n",
    "\"train data converted into a panda DataFrame\"\n",
    "test = pd.read_table(DATA_TEST, header=0)\n",
    "testlabel = pd.read_table(LABEL_TEST, header=0)\n",
    "\"test data converted into a panda DataFrame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a TfidfVectorizer object\n",
    "#with word features, no stop words, lowercased documents, some ignored too frequent terms (>0.9), no maximum features,  \n",
    "#with smooth idf weight, sublinear tf scaling and enabled inverse_document_frequency reweighting, \n",
    "#normalized with l1 norm\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "    \n",
    "#instantiate a MultinomialNB object\n",
    "#that learn the class prior probabilities from the train dataset\n",
    "#with an additive Laplace smotthing parameter alpha = 1.0\n",
    "\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweet index', 'tweet text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#How to handle dataframes\n",
    "#print(train.columns)\n",
    "#print(train['Tweet text'])\n",
    "\n",
    "#print(train['Label'])\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nb(train_data, train_target):\n",
    "    #parameters: \n",
    "    ##the train dataset\n",
    "    ##the classification labels of the train set\n",
    "    #returns: an object of the class MultinomialNB, containing the probabilities needed to classify new instances\n",
    "    ###\n",
    "   \n",
    "    #tokenize and build vocabulary on the train set\n",
    "    #encode the raw documents into a sparse matrix X[n_sample, n_features]\n",
    "    X_train_tfidf = tfidfvectorizer.fit_transform(train_data)\n",
    "    \n",
    "    #fit a Multinomial Naive Bayes classifier on the train set of targetet features\n",
    "    mnb_classif = mnb.fit(X_train_tfidf, train_target)\n",
    "    print(\"clf trained\")\n",
    "    return mnb_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a new document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Day ninth December to have a pint at the boars head| really still in bed :smiling_face_with_smiling_eyes: http://t.co/H4XoH4jpwc']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#taking a randomly chosen sample of the test set\n",
    "row = random.choice(test['tweet index'])\n",
    "#print(row)[\n",
    "rd_data = test.loc[row,:]\n",
    "rd_data = [rd_data['tweet text']]\n",
    "print(rd_data)\n",
    "print(type(rd_data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nb(classifier, document):\n",
    "    #parameters:\n",
    "    ##classifier: an object of the class MultinomialNB, containing the probabilities needed to classify a new instance\n",
    "    ##document: the text file that we want to classify, already tokenized \n",
    "    #returns: the prediction of the classifier\n",
    "    \n",
    "    #tokenize the test sample\n",
    "    #encode the raw documents into a sparse matrix \n",
    "    X_test_sample_tfidf = tfidfvectorizer.transform(document)\n",
    "    #print(X_test_tfidf)\n",
    "\n",
    "    #predictions on the test set\n",
    "    predicted = classifier.predict(X_test_sample_tfidf)\n",
    "    print(\"prediction :\")\n",
    "    \n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf trained\n",
      "prediction :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained = train_nb(train['Tweet text'], train['Label'])\n",
    "\n",
    "classify_nb(trained, rd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     ironic       0.77      0.60      0.67       473\n",
      " non ironic       0.54      0.73      0.62       311\n",
      "\n",
      "avg / total       0.68      0.65      0.65       784\n",
      "\n",
      "0.6505102040816326\n",
      "Wall time: 20.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tokenize the test set\n",
    "#encode the raw documents into a sparse matrix \n",
    "X_test_tfidf = tfidfvectorizer.transform(test['tweet text'])\n",
    "#print(X_test_tfidf)\n",
    "\n",
    "#predictions on the test set\n",
    "predicted = trained.predict(X_test_tfidf)\n",
    "\n",
    "#performance of the NB classifier\n",
    "print(classification_report(testlabel['Label'], predicted, target_names = ['ironic','non ironic']))\n",
    "\n",
    "acc = accuracy_score(testlabel['Label'], predicted)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
